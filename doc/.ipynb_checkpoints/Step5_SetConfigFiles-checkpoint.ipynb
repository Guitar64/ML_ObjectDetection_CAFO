{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:purple\">GIS and Machine Learning for Object Detection in Satellite Imagery</span>\n",
    "\n",
    "<img src=\"img/robot.jpg\"></img>\n",
    "\n",
    "## <span style=\"color:blue\">Step 5: Set up a configuration file containing CNN hyperparameters and a label file containing your object classes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks are great for learning a variety of patterns. How effective the neural network is at identifying any given pattern is often determined by the architecture of the Neural Network. In this step, we will create a configuration file that stores the values, or hyperparameters, that determine the architecture and behavior of the neural network.\n",
    "\n",
    "To understand hyperparameters, let's briefly (and broadly) revisit how neural networks operate..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/simple_neural_network.jpg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadly speaking, the purpose of the architecture of the neural network is to help break down large problems into smaller problems that can be solved by smaller segments of the network. For instance, let's take a look at this simplified neural network that determines if an input image has a dog:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/dogneuralnetwork.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With respect to simple neural networks, there are two immediate terms that we will cover:\n",
    "\n",
    "##### FeedForward and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeedForward\n",
    "\n",
    "As data flows through the network, each neuron has a vote in the activation of its connected neurons, until the signals make it to the output layer. The feeding of data from the input layer through the hidden layers to the output layer is an action termed \"FeedForward\".\n",
    "\n",
    "The connections between each neuron have a corresponding weight to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/nn01.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Backpropagation\n",
    "\n",
    "The \"magic\" of Machine Learning is actually in the learning process that occurs on each FeedForward iteration during training epochs. \n",
    "\n",
    "During training, we will pass our training data through the network's layers and take a guess. This guess will almost certainly be completely off the mark. \n",
    "\n",
    "We know the correct answer and we know that the neural network made a wrong guess, so now we need to determine which neural connections and weights contributed the most to the error in our guess.\n",
    "\n",
    "Our goal with backpropagation is to update each of the weights in the network so that they cause the actual output to be closer the target output, thereby minimizing the error for each output neuron and the network as a whole.\n",
    "\n",
    "We want to adjust the weights so that the error in the output is as low as possible. \n",
    "\n",
    "One of the ways this can occur is through gradient descent, which we'll mention briefly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/gradientdescent.JPG\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation gradually adjusts the weights in the connections over iterations to very gradually adjust each weight in each connection to minimize the error across the entire network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/nnweights.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch\n",
    "\n",
    "FeedForward + Backpropagation = Epoch\n",
    "\n",
    "\n",
    "Each iteration of FeedForward and Backpropagation during training is referred to as an Epoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.75188&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few examples of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate\n",
    "Learning rate controls how much to update the weight in the optimization algorithm. \n",
    "\n",
    "<img src=\"img/gradient.jpg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of epochs\n",
    "Number of epochs is the the number of times the entire training set pass through the neural network. We should generally start with a high amount of epochs to determine at which point the neural network is done minimizing the error across the weights in the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size\n",
    "Determines the number of training samples in one FeedForward and Backpropagation pass. The higher the batch size, the more memory space in your GPU you will need. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation function\n",
    "The function used to determine if a neuron will \"fire\" or not. \n",
    "\n",
    "<img src=\"img/relu.png\" style=\"width:50%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of hidden layers \n",
    "The architecture of the neural network. Generally, more layers result in a more accurate neural network, but the trade off is that it is computationally expensive to train the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are many others..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So now, let's store the default hyperparameter values in a configuration file which will be used as an input when we start training the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For help with setting up your own configuration file, refer to the TensorFlow documentation. \n",
    "\n",
    "Alternatively, you may use the configuration file we used and is available in this repo. If you use the config file attached, be sure to alter the PATH_TO_BE_CONFIGURED variables to reference your workspace. \n",
    "\n",
    "You may also want to change your batch size, depending on your GPU's VRAM. The default of 24 should work for fairly modern systems with powerful graphics cards, but if you experience a memory error, you may want to test with a lower batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the following was my config file at the completion of this step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SSD with Mobilenet v1, configured for the cafo dataset.\n",
    "\n",
    "model {\n",
    "  ssd {\n",
    "    num_classes: 1    # Number of classes in your dataset.\n",
    "    box_coder {\n",
    "      faster_rcnn_box_coder {\n",
    "        y_scale: 10.0\n",
    "        x_scale: 10.0\n",
    "        height_scale: 5.0\n",
    "        width_scale: 5.0\n",
    "      }\n",
    "    }\n",
    "    matcher {\n",
    "      argmax_matcher {\n",
    "        matched_threshold: 0.5\n",
    "        unmatched_threshold: 0.5\n",
    "        ignore_thresholds: false\n",
    "        negatives_lower_than_unmatched: true\n",
    "        force_match_for_each_row: true\n",
    "      }\n",
    "    }\n",
    "    similarity_calculator {\n",
    "      iou_similarity {\n",
    "      }\n",
    "    }\n",
    "    anchor_generator {\n",
    "      ssd_anchor_generator {\n",
    "        num_layers: 6\n",
    "        min_scale: 0.2\n",
    "        max_scale: 0.95\n",
    "        aspect_ratios: 1.0\n",
    "        aspect_ratios: 2.0\n",
    "        aspect_ratios: 0.5\n",
    "        aspect_ratios: 3.0\n",
    "        aspect_ratios: 0.3333\n",
    "      }\n",
    "    }\n",
    "    image_resizer {\n",
    "      fixed_shape_resizer {\n",
    "        height: 300\n",
    "        width: 300\n",
    "      }\n",
    "    }\n",
    "    box_predictor {\n",
    "      convolutional_box_predictor {\n",
    "        min_depth: 0\n",
    "        max_depth: 0\n",
    "        num_layers_before_predictor: 0\n",
    "        use_dropout: false\n",
    "        dropout_keep_probability: 0.8\n",
    "        kernel_size: 1\n",
    "        box_code_size: 4\n",
    "        apply_sigmoid_to_scores: false\n",
    "        conv_hyperparams {\n",
    "          activation: RELU_6,\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "              weight: 0.00004\n",
    "            }\n",
    "          }\n",
    "          initializer {\n",
    "            truncated_normal_initializer {\n",
    "              stddev: 0.03\n",
    "              mean: 0.0\n",
    "            }\n",
    "          }\n",
    "          batch_norm {\n",
    "            train: true,\n",
    "            scale: true,\n",
    "            center: true,\n",
    "            decay: 0.9997,\n",
    "            epsilon: 0.001,\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    feature_extractor {\n",
    "      type: 'ssd_mobilenet_v1'\n",
    "      min_depth: 16\n",
    "      depth_multiplier: 1.0\n",
    "      conv_hyperparams {\n",
    "        activation: RELU_6,\n",
    "        regularizer {\n",
    "          l2_regularizer {\n",
    "            weight: 0.00004\n",
    "          }\n",
    "        }\n",
    "        initializer {\n",
    "          truncated_normal_initializer {\n",
    "            stddev: 0.03\n",
    "            mean: 0.0\n",
    "          }\n",
    "        }\n",
    "        batch_norm {\n",
    "          train: true,\n",
    "          scale: true,\n",
    "          center: true,\n",
    "          decay: 0.9997,\n",
    "          epsilon: 0.001,\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    loss {\n",
    "      classification_loss {\n",
    "        weighted_sigmoid {\n",
    "          anchorwise_output: true\n",
    "        }\n",
    "      }\n",
    "      localization_loss {\n",
    "        weighted_smooth_l1 {\n",
    "          anchorwise_output: true\n",
    "        }\n",
    "      }\n",
    "      hard_example_miner {\n",
    "        num_hard_examples: 3000\n",
    "        iou_threshold: 0.99\n",
    "        loss_type: CLASSIFICATION\n",
    "        max_negatives_per_positive: 3\n",
    "        min_negatives_per_image: 0\n",
    "      }\n",
    "      classification_weight: 1.0\n",
    "      localization_weight: 1.0\n",
    "    }\n",
    "    normalize_loss_by_num_matches: true\n",
    "    post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 1e-8\n",
    "        iou_threshold: 0.6\n",
    "        max_detections_per_class: 100\n",
    "        max_total_detections: 100\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_config: {\n",
    "  batch_size: 10\n",
    "  optimizer {\n",
    "    rms_prop_optimizer: {\n",
    "      learning_rate: {\n",
    "        exponential_decay_learning_rate {\n",
    "          initial_learning_rate: 0.004\n",
    "          decay_steps: 800720\n",
    "          decay_factor: 0.95\n",
    "        }\n",
    "      }\n",
    "      momentum_optimizer_value: 0.9\n",
    "      decay: 0.9\n",
    "      epsilon: 1.0\n",
    "    }\n",
    "  }\n",
    "  fine_tune_checkpoint: \"ssd_mobilenet_v1_coco_11_06_2017/model.ckpt\"\n",
    "  from_detection_checkpoint: true\n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    ssd_random_crop {\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"data/train.record\"\n",
    "  }\n",
    "  label_map_path: \"data/object-detection.pbtxt\"\n",
    "}\n",
    "\n",
    "eval_config: {\n",
    "  num_examples: 40\n",
    "}\n",
    "\n",
    "eval_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"data/test.record\"\n",
    "  }\n",
    "  label_map_path: \"training/object-detection.pbtxt\"\n",
    "  shuffle: false\n",
    "  num_readers: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config file is used by TensorFlow's \"model_builder.py\" module in the \"_build_ssd_model\" method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/models/blob/a4944a57ad2811e1f6a7a87589a9fc8a776e8d3c/object_detection/builders/model_builder.py#L108"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this step should be a .config file stored in your workplace.\n",
    "\n",
    "https://github.com/Qberto/ML_ObjectDetection_CAFO/blob/master/training/ssd_mobilenet_v1_cafo.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label file is a much simpler process... in fact here's the entire contents of the one we used:\n",
    "\n",
    "```\n",
    "item { id: 1 name: 'cafo' }\n",
    "```\n",
    "\n",
    "This one can be found at training/object-detection.pbtxt.\n",
    "\n",
    "https://github.com/Qberto/ML_ObjectDetection_CAFO/blob/master/training/object-detection.pbtxt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
